<<<<<<< Updated upstream
View(anfragen)
setwd("C:/Users/Felix/OneDrive - bwedu/Documents/Studium/AG Breunig/Ben/scraping_felix/R")
austrian <- read.csv("data/indexpagedata", header = TRUE)
austrian <- read.csv("data/indexpagedata.csv", header = TRUE)
View(austrian)
load("C:/Users/Felix/OneDrive - bwedu/Documents/Studium/AG Breunig/Ben/scraping_felix/R/data/proposalpage.RData")
View(indexpagedata)
View(data1)
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, furrr, rvest, ggthemes, lubridate, rio, haven)
test <- read_html("https://www.parlament.gv.at/PAKT/VHG/XXIV/A/A_02177/index.shtml")
test
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[2] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[2] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text()
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test <- read_html("https://www.parlament.gv.at/PAKT/VHG/XXIV/A/A_02363/index.shtml")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test <- read_html("https://www.parlament.gv.at/PAKT/VHG/XXIV/I/I_02548/index.shtml")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.]")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+")
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim()
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T) %>%
str_subset("\\s{3,}", negate = T)
test %>% html_nodes("div.c_2 p") %>%
html_text() %>%
str_remove_all("[^A-Za-z0-9 ÄÖÜäöü:.-]") %>% .[-1] %>%
str_extract(":.+") %>%
str_extract("[A-Z].+") %>%
str_trim() %>%
str_subset("[0-9]{3}", negate = T)
knitr::opts_chunk$set(echo = TRUE)
all_indexpagedata <- dir("data", pattern = "_X", full.names = T) %>%
map_dfr(readr::read_csv) %>%
select(-X1)
readr::write_csv(all_indexpagedata, "data/indexpagedata.csv")
all_indexpagedata <- dir("data", pattern = "_X", full.names = T) %>%
map_dfr(readr::read_csv) %>%
select(-X1)
readr::write_csv(all_indexpagedata, "data/indexpagedata.csv")
indexpagedata <- readr::read_csv(file = "data/indexpagedata.csv") %>%
mutate_all(as.character)
=======
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message(.y)}
out <- try(get_meta_info(.x))
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
hello <- character(0)
hello
hello %>% fix_obj()
NA %>% str_detect(., "ff")
heffo %>% str_detect(., "ff")
1 <- NA
t1 <- NA
t1
t2 <- heffo
t2 <- "heffo"
t1 %>% str_detect(., "ff")
t2 %>% str_detect(., "ff")
hello %>% str_detect(., "ff")
hello
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
fix_obj(pattern = "kein link")
map(~{
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
fix_obj(pattern = character(1))
map(~{
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
fix_obj(pattern = "kein link") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
rlang::last_error()
.x
indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/")
indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/")) %>%
.[1:15,]
testdata
testdata$bill_download
testdata <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/")) %>%
.[1:100,]
testdata$bill_download
testdata <- indexpagedata %>%
left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata$bill_download %>% unique()
testdata$bill_link %>% unique()
testdata$proposal_download %>% unique()
testdata$resolution_NR %>% unique()
testdata <- indexpagedata %>%
+     left_join(proposalpagedata) %>%
+     mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
+            bill_download = bill_link %>%
+                str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata <- indexpagedata %>%
+     left_join(proposalpagedata) %>%
+     mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
+            bill_download = bill_link %>%
+                str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata <- indexpagedata %>%
+     left_join(proposalpagedata) %>%
+     mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
+            bill_download = bill_link %>%
+                str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/")
indexpagedata %>%
+     left_join(proposalpagedata) %>%
+     mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
+            bill_download = bill_link %>%
+                str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
indexpagedata %>%     left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
+            bill_download = bill_link %>%
+                str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
indexpagedata %>%     left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata <- indexpagedata %>%     left_join(proposalpagedata) %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/"))
testdata$resolution_NR %>% unique()
testdata$proposal_download %>% unique()
testdata$bill_link %>% unique()
testdata$bill_download %>% unique()
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message(.y)}
out <- try(get_meta_info(.x))
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
?imap_dfr
>>>>>>> Stashed changes
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
<<<<<<< Updated upstream
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
map_dfr(get_meta_info)
proposalpagedata
=======
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message(.y)}
out <- try(get_meta_info(.x))
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
proposalpagedata
split(proposalpagedata, 1:nrow(proposalpagedata))
1 %% 100
1 %% 100 == 1
2 %% 100 == 1
proposalpagedata
split(proposalpagedata, 1:nrow(proposalpagedata))
>>>>>>> Stashed changes
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
<<<<<<< Updated upstream
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
map_dfr(get_meta_info)
get_meta_info
devtools::install_github("saschagobel/legislatoR")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("saschagobel/legislatoR")
devtools::install_github("saschagobel/legislatoR")
get_de
get_de()
library(legislatoR)
get_de()
get_political()
get_political_de
get_political(de)
get_political("de")
get_political("deu")
legis_de <- as_tibble(get_political("deu"))
legis_de
get_core(deu)
get_core("deu")
add_column(legis_de, get_core("deu"))
legis_de <- as_tibble(get_core("deu"))
legis_de
anfragen
anfragen$Anfragesteller
legis_de
legis_de <- left_join(x = legis_de,
y = get_political(legislature = "deu"),
by = "pageid")
legis_de
getOption("repos")
install.packages("caTools")
install.packages("installr")
installr::updateR()
install.packages("caTools")
=======
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message(.y)}
out <- try(get_meta_info(.x))
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
200 %% 100 == 1
100 %% 100 == 1
99 %% 100 == 1
101 %% 100 == 1
102 %% 100 == 1
201 %% 100 == 1
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one")}
out <- try(get_meta_info(.x))
wait(1.5)
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
-> testdata
proposalpagedata$verfahren
source("utils.R")
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
wait(1.5)
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
source(utils.R)
source("utils.R")
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
wait(1.5)
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
wait(1.5)
glimpse(out)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
glimpse(out)
wait(1.5)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
source("utils.R")
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
glimpse(out)
wait(1.5)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
source("utils.R")
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
glimpse(out)
wait(1.5)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
proposalpagedata$verfahren
source("utils.R")
proposalpagedata <- indexpagedata %>%
mutate(.id = 1:n()) %>%
# sample_n(10) %>%
split(1:nrow(.)) %>%
.[1:20] %>%
# I put the scraping code in a function, which is sourced from the script utils.R
# Map is more efficient than for loop
# It take the  providedfunction and apply it to each element of the input
imap_dfr(~{
print(.x$proposal_link)
if(as.numeric(.y) %% 100 == 1){message("another one (hunnid) - DJ Khaled")}
out <- try(get_meta_info(.x))
glimpse(out)
wait(1.5)
if(inherits(out, "try-error")){return(tibble( .id = .x$.id, proposal_link = .x$proposal_link))}
return(out)
})
proposalpagedata$verfahren
proposalpagedata$resolution_NR
proposalpagedata$resolution_NR[5]
proposalpagedata$proposal_link[5]
proposalpagedata$resolution_NR[11]
proposalpagedata$proposal_link[11]
test <- read_html("https://www.parlament.gv.at/PAKT/VHG/XX/I/I_02056/index.shtml")
test %>%
html_node("div.floatLeft p") %>%
html_text() %>%
str_to_lower() %>%
str_extract("dag[A-Za-z:\\s,]+") %>%
gsub("[^A-Za-z0-9]", "" , .) %>%
str_sub(start = 8L, end = -1L) %>%
str_split("")
proposalpagedata$proposal_link[5]
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
rlang::last_error()
data <- indexpagedata %>%
left_join(proposalpagedata
)
data
data <- indexpagedata %>%
left_join(proposalpagedata) %>%.[1:20,]
data
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
case_when()
?case_when()
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
case_when(str_detect(.x, "PAKT") != 1 ~ return(NA_character_)
is.na(.x) == 1 ~ return(NA_character_))
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
case_when(str_detect(.x, "PAKT") != 1 ~ return(NA_character_),
is.na(.x) == 1 ~ return(NA_character_))
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
case_when(str_detect(.x, "PAKT") != 1 ~ return(NA_character_),
is.na(.x) == 1 ~ return(NA_character_))
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
data <- indexpagedata %>%
left_join(proposalpagedata) %>%
.[1:20, ] %>%
mutate(proposal_download = paste0("www.parlament.gv.at", proposal_download),
bill_download = bill_link %>%
str_replace("^\\/(?<=PAKT)", "https://www.parlament.gv.at/") %>%
map(~{
if(str_detect(.x, "PAKT") != 1) {return(NA_character_)}
wait(1.5)
.x %>%
read_html %>%
html_nodes("ul.fliesstext li a") %>%
html_attr("href") %>%
str_subset("\\d.html") %>%
.[1] %>%
paste0("www.parlament.gv.at", .)
}))
>>>>>>> Stashed changes
